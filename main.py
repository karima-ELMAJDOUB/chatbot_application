# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xM9wUeWSJMFRzAwpgOvlQLiOt-FAa3ZK
"""

from preprocessing import preprocess_data
from training import train_model
from testing import load_chatbot_model, chatbot_response
import random
import json
import numpy as np


# Preprocess data
data_file_path = '/content/intents.json'
words, classes, documents_lemmatized = preprocess_data(data_file_path)

# Create training data
training = []
output_empty = [0] * len(classes)
for doc in documents_lemmatized:
    bag = []
    for w in words:
        bag.append(1) if w in doc.split() else bag.append(0)
    output_row = list(output_empty)
    training.append([bag, output_row])

# Shuffle training
random.shuffle(training)

train_x = [item[0] for item in training]
train_y = [item[1] for item in training]

# Train model
model = train_model(train_x, train_y, classes)

# Load intents from file
with open('/content/intents.json', 'r') as file:
    intents = json.load(file)

# Test model
test_sentence = "What can you do?"
response = chatbot_response(test_sentence, model, words, classes, intents)
print(response)